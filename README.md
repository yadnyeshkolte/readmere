# ğŸ§Ÿâ€â™‚ï¸ README Resurrector

> **Bring dead documentation back to life.** Paste a GitHub URL â€” five AI agents analyze your repo, read the code, generate a professional README, score it, and improve it â€” all in seconds.

[![Built with Archestra](https://img.shields.io/badge/Built%20with-Archestra-00d4aa?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJ3aGl0ZSI+PGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMTAiLz48L3N2Zz4=)](https://archestra.ai)
[![Powered by Gemini](https://img.shields.io/badge/Powered%20by-Gemini%202.5%20Flash-4285F4?style=for-the-badge&logo=google&logoColor=white)](https://aistudio.google.com)
[![MCP Protocol](https://img.shields.io/badge/Protocol-MCP-blue?style=for-the-badge)](https://modelcontextprotocol.io)
[![2 Fast 2 MCP](https://img.shields.io/badge/Hackathon-2%20Fast%202%20MCP-red?style=for-the-badge)](https://devpost.com)

---

## ğŸï¸ What is README Resurrector?

README Resurrector is a **multi-agent MCP system** that automatically generates comprehensive, professional-grade README documentation for any GitHub repository. Instead of one monolithic AI, it uses **five specialized AI agents** orchestrated through the **Archestra MCP Platform**:

```
GitHub URL â†’ [Repo Analyzer] â†’ [Code Reader] â†’ [Doc Generator] â†’ [Scorer] â†’ [Improver] â†’ README.md âœ¨
                 MCP #1           MCP #2           MCP #3          MCP #4      MCP #5
                   â†‘                â†‘                â†‘               â†‘           â†‘
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Archestra Platform â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Every developer knows the pain: you find a promising open-source repo, but the README is outdated, incomplete, or missing entirely. README Resurrector solves this by **automatically analyzing** the code, **understanding the architecture**, and **generating polished documentation** â€” complete with quality scoring and iterative improvement.

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    User[ğŸ§Ÿâ€â™‚ï¸ User] --> Frontend[Next.js Frontend]
    Frontend --> Backend[Express Backend<br/>Port 7860]
    Backend --> Archestra[Archestra Service]
    
    subgraph "MCP Servers"
        RA[ğŸ” Repo Analyzer<br/>Port 3002]
        CR[ğŸ“– Code Reader<br/>Port 3003]
        DG[âœï¸ Doc Generator<br/>Port 3004]
        RS[ğŸ“Š README Scorer<br/>Port 3005]
        RI[âœ¨ README Improver<br/>Port 3006]
    end
    
    Archestra --> RA
    Archestra --> CR
    Archestra --> DG
    Archestra --> RS
    Archestra --> RI
    
    DG --> Gemini[Gemini 2.5 Flash<br/>via Google AI]
    RS --> Gemini
    RI --> Gemini
    
    style Archestra fill:#10b981,color:#000
    style Gemini fill:#4285F4,color:#fff
```

### The Five Agents

| Agent | MCP Server | Port | Purpose | Key Tools |
|-------|-----------|------|---------|-----------|
| ğŸ” **Repo Analyzer** | `repo-analyzer` | 3002 | Crawls GitHub repos via API, maps file trees, identifies tech stack | `analyze_repository`, `get_repo_metadata`, `identify_important_files` |
| ğŸ“– **Code Reader** | `code-reader` | 3003 | Reads files, extracts function signatures, intelligently chunks code for LLM context | `read_files`, `extract_signatures`, `smart_chunk` |
| âœï¸ **Doc Generator** | `doc-generator` | 3004 | Generates comprehensive README using Gemini 2.5 Flash with custom instructions support | `generate_readme` |
| ğŸ“Š **README Scorer** | `readme-scorer` | 3005 | Validates README quality across 5 weighted categories (100-point scale) | `validate_readme` |
| âœ¨ **README Improver** | `readme-improver` | 3006 | Enhances README based on scoring suggestions, preserving existing content | `enhance_readme` |

## âš¡ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 14, TypeScript, CSS (dark theme, glassmorphism) |
| **Backend** | Express.js, TypeScript, Server-Sent Events (SSE) |
| **AI Model** | Gemini 2.5 Flash via [Google AI Studio](https://aistudio.google.com) (fast, generous free tier) |
| **Protocol** | [Model Context Protocol (MCP)](https://modelcontextprotocol.io) |
| **Orchestration** | [Archestra Platform](https://archestra.ai) |
| **Transport** | Streamable HTTP + SSE (dual-transport support) |
| **Deployment** | Hugging Face Spaces (Docker) + Vercel |

## ğŸ¯ How It Works (Step by Step)

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant RA as Repo Analyzer
    participant CR as Code Reader
    participant DG as Doc Generator
    participant RS as README Scorer
    participant RI as README Improver
    
    U->>F: Paste GitHub URL + optional instructions
    F->>B: POST /api/generate (SSE stream)
    
    B->>RA: get_repo_metadata(repoUrl)
    RA-->>B: {name, stars, language, description}
    
    B->>RA: analyze_repository(repoUrl)
    RA-->>B: {fileTree, languageBreakdown, keyFiles}
    
    B->>RA: identify_important_files(fileTree)
    RA-->>B: ["src/index.ts", "package.json", ...]
    
    B->>CR: read_files(repoUrl, filePaths)
    CR-->>B: [{path, content}, ...]
    
    B->>CR: extract_signatures(files)
    CR-->>B: [{file, signatures: [{name, type, params}]}]
    
    B->>CR: smart_chunk(files, maxTokens=12000)
    CR-->>B: [{file, chunk}] (LLM-optimized)
    
    B->>DG: generate_readme(metadata, analysis, chunks, signatures, userPrompt)
    DG-->>B: "# Project Name\n..."
    
    B->>RS: validate_readme(readme)
    RS-->>B: {score: 85, categories: {...}, suggestions: [...]}
    
    alt score < 80
        B->>RI: enhance_readme(readme, suggestions)
        RI-->>B: "# Improved README\n..."
    end
    
    B-->>F: SSE events (progress + final result)
    F-->>U: Rendered README + quality report
```

### The Quality Scoring System

READMEs are scored across **5 weighted categories**:

| Category | Weight | What It Measures |
|----------|--------|-----------------|
| **Completeness** | 30% | All essential sections present (title, description, install, usage, features, contributing, license) |
| **Accuracy** | 25% | Code examples work, correct tech stack, accurate commands |
| **Structure** | 20% | Proper markdown, logical section order, heading hierarchy |
| **Readability** | 15% | Clear language, good flow, appropriate detail level |
| **Visual Appeal** | 10% | Badges, emoji, tables, syntax-highlighted code blocks |

Users can click **"âœ¨ Improve Score"** to re-enhance the README based on the specific suggestions. Visit `/score` in the app for the full methodology.

## ğŸš€ Quick Start

### Prerequisites
- Node.js 20+
- GitHub Personal Access Token ([create one](https://github.com/settings/tokens))
- Gemini API Key ([get one free](https://aistudio.google.com/apikey))

### Local Development

```bash
# Clone
git clone https://github.com/yadnyeshkolte/readmere.git
cd readmere

# Install dependencies for all services
cd mcp-servers/repo-analyzer && npm install && cd ../..
cd mcp-servers/code-reader && npm install && cd ../..
cd mcp-servers/doc-generator && npm install && cd ../..
cd mcp-servers/readme-scorer && npm install && cd ../..
cd mcp-servers/readme-improver && npm install && cd ../..
cd backend && npm install && cd ..
cd frontend && npm install && cd ..

# Set environment variables
cp .env.example .env
# Edit .env with your GEMINI_API_KEY and GITHUB_TOKEN

# Start all 5 MCP servers
PORT=3002 GITHUB_TOKEN=$GITHUB_TOKEN npx tsx mcp-servers/repo-analyzer/src/index.mts &
PORT=3003 GITHUB_TOKEN=$GITHUB_TOKEN npx tsx mcp-servers/code-reader/src/index.mts &
PORT=3004 GEMINI_API_KEY=$GEMINI_API_KEY npx tsx mcp-servers/doc-generator/src/index.mts &
PORT=3005 GEMINI_API_KEY=$GEMINI_API_KEY npx tsx mcp-servers/readme-scorer/src/index.mts &
PORT=3006 GEMINI_API_KEY=$GEMINI_API_KEY npx tsx mcp-servers/readme-improver/src/index.mts &

# Start backend
cd backend && npm run dev &

# Start frontend
cd frontend && npm run dev
```

### Docker (Recommended)

```bash
docker-compose up --build
```

This starts all 5 MCP servers, the backend, and the Archestra platform.

## ğŸ“ Project Structure

```
readmere/
â”œâ”€â”€ frontend/                        # Next.js 14 frontend
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ page.tsx                # Landing page
â”‚   â”‚   â”œâ”€â”€ generate/page.tsx       # Generation page (SSE progress, preview, quality)
â”‚   â”‚   â”œâ”€â”€ score/page.tsx          # Score methodology page
â”‚   â”‚   â””â”€â”€ layout.tsx              # Root layout (favicon, fonts)
â”‚   â””â”€â”€ src/components/
â”‚       â”œâ”€â”€ URLInput.tsx            # URL input + custom instructions
â”‚       â”œâ”€â”€ ProgressTracker.tsx     # 4-step progress UI
â”‚       â”œâ”€â”€ ReadmePreview.tsx       # Markdown preview + copy/download
â”‚       â”œâ”€â”€ Header.tsx              # Navigation
â”‚       â””â”€â”€ Footer.tsx              # Footer
â”‚
â”œâ”€â”€ readmere-huggingface-engine/     # ğŸ³ HF Space deployment (everything below)
â”‚   â”œâ”€â”€ Dockerfile                  # Builds & starts all 5 MCP servers + backend
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ index.ts            # Express server
â”‚   â”‚       â”œâ”€â”€ routes/generate.ts  # /api/generate + /api/generate/improve
â”‚   â”‚       â”œâ”€â”€ agents/orchestrator.ts  # Pipeline orchestration
â”‚   â”‚       â”œâ”€â”€ services/archestra.ts   # MCP client (toolâ†’port routing)
â”‚   â”‚       â””â”€â”€ utils/json.ts       # Safe JSON parser
â”‚   â””â”€â”€ mcp-servers/
â”‚       â”œâ”€â”€ repo-analyzer/          # MCP #1: GitHub repo analysis
â”‚       â”œâ”€â”€ code-reader/            # MCP #2: File reading & chunking
â”‚       â”œâ”€â”€ doc-generator/          # MCP #3: README generation (LLM)
â”‚       â”œâ”€â”€ readme-scorer/          # MCP #4: Quality scoring (LLM)
â”‚       â””â”€â”€ readme-improver/        # MCP #5: Enhancement (LLM)
â”‚
â”œâ”€â”€ backend/                        # Mirror of readmere-huggingface-engine/backend
â”œâ”€â”€ mcp-servers/                    # Mirror of readmere-huggingface-engine/mcp-servers
â”œâ”€â”€ archestra-platform/             # Archestra HF Space config
â”œâ”€â”€ PROGRESS.md                     # Project state (AI agent context)
â”œâ”€â”€ ARCHITECTURE.md                 # Deep technical documentation
â”œâ”€â”€ DEPLOYMENT.md                   # Deployment guide
â””â”€â”€ docker-compose.yml              # Full stack orchestration
```

## ğŸ”Œ MCP Transport & Archestra Integration

Each MCP server supports **dual transport**:

- **Streamable HTTP** (`POST /mcp`) â€” Modern, session-based, preferred
- **SSE** (`GET /sse` + `POST /messages`) â€” Legacy fallback

The **Archestra Service** (`backend/src/services/archestra.ts`) manages connections:
- Maintains a `toolâ†’port` routing map
- Caches MCP client connections per port
- Auto-retries with fresh connections on failure
- Supports both Streamable HTTP and SSE transports

### Archestra Platform Features Used
- âœ… MCP Server Registration & Management
- âœ… Multi-agent orchestration (5 agents)
- âœ… Streamable HTTP transport
- âœ… Built-in Chat UI for agent interaction
- âœ… Centralized runtime
- âœ… Platform observability

## ğŸ§ª API Endpoints

### `POST /api/generate`
Generates a README for a GitHub repository.

**Request**:
```json
{
  "repoUrl": "https://github.com/owner/repo",
  "userPrompt": "Focus on API documentation, add deployment guide"
}
```

**Response**: Server-Sent Events stream with `progress` and `result` events.

### `POST /api/generate/improve`
Improves an existing README based on suggestions.

**Request**:
```json
{
  "readme": "# Existing README content...",
  "suggestions": "Add installation steps, include badges, fix code examples"
}
```

**Response**:
```json
{
  "readme": "# Improved README...",
  "quality": { "score": 92, "categories": {...}, "suggestions": [...] }
}
```

## ğŸ Hackathon: 2 Fast 2 MCP

This project was built for the **[2 Fast 2 MCP Hackathon](https://devpost.com)** organized by Archestra.

### Why 5 MCP Servers?

Instead of one monolithic agent doing everything, we split responsibilities into **purpose-built specialists**:

1. **Repo Analyzer** focuses solely on GitHub API interaction â€” no LLM needed
2. **Code Reader** handles file I/O and intelligent chunking â€” no LLM needed
3. **Doc Generator** is the creative writer â€” uses Gemini 2.5 Flash
4. **README Scorer** is the quality checker â€” independent LLM evaluation
5. **README Improver** acts on feedback â€” targeted LLM enhancement

This separation means each agent can be **tested, scaled, and improved independently**. It also prevents context contamination â€” the scorer doesn't know what instructions were given to the generator.

---

<p align="center">
  <b>ğŸ§Ÿâ€â™‚ï¸ Stop writing READMEs from scratch. Let the dead docs rise again.</b>
</p>

<p align="center">
  Built with â¤ï¸ for the 2 Fast 2 MCP Hackathon
</p>
